{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d713b242-fcd3-4891-8579-43d4ee2a4970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] PDF -> /Users/noenotter/Documents/Summer_intern/outputs/NGFS_Heatmaps_Transition_Cost.pdf\n",
      "[OK] PNGs -> /Users/noenotter/Documents/Summer_intern/outputs/NGFS_Eq9_png\n",
      "[OK] Standardized exports -> /Users/noenotter/Documents/Summer_intern/outputs/transition\n",
      "[OK] PDF -> /Users/noenotter/Documents/Summer_intern/outputs/NGFS_Heatmaps_Transition_Cost_BAU20_r2pct.pdf\n",
      "[OK] PNGs -> /Users/noenotter/Documents/Summer_intern/outputs/NGFS_Eq9_BAU20_r2pct_png\n",
      "[OK] Standardized exports -> /Users/noenotter/Documents/Summer_intern/outputs/transition\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Eq. (9) — BAU-normalized transition cost (EXPORTS REFACTORED ONLY)\n",
    "# - Calculations and plotting identical to your current workflow.\n",
    "# - Adds standardized exports for Streamlit (PNG + CSV wide + CSV long).\n",
    "# ==========================================================\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from pathlib import Path\n",
    "\n",
    "# --------------------------- CONFIG ---------------------------\n",
    "ROOT = os.path.expanduser(\"~/Documents/Summer_intern\")\n",
    "EMISSIONS_XLSX = os.path.join(ROOT, \"NGFS_GCAM_Carbon_Emissions_Sectors.xlsx\")\n",
    "PRICES_XLSX = os.path.join(ROOT, \"NGFS_GCAM_Price_Carbons.xlsx\")\n",
    "\n",
    "OUTDIR = os.path.join(ROOT, \"outputs\"); os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# Legacy outputs (kept for backward compatibility)\n",
    "PDF_OUT_MAIN = os.path.join(OUTDIR, \"NGFS_Heatmaps_Transition_Cost.pdf\")\n",
    "PNG_DIR_MAIN = os.path.join(OUTDIR, \"NGFS_Eq9_png\"); os.makedirs(PNG_DIR_MAIN, exist_ok=True)\n",
    "\n",
    "PDF_OUT_20 = os.path.join(OUTDIR, \"NGFS_Heatmaps_Transition_Cost_BAU20_r2pct.pdf\")\n",
    "PNG_DIR_20 = os.path.join(OUTDIR, \"NGFS_Eq9_BAU20_r2pct_png\"); os.makedirs(PNG_DIR_20, exist_ok=True)\n",
    "\n",
    "# New standardized tree for Streamlit (added; calculations unchanged)\n",
    "STD_ROOT = Path(ROOT) / \"outputs\" / \"transition\"  # base for standardized exports\n",
    "\n",
    "BAU_SCEN = \"Current Policies\"  # b\n",
    "NZ_SCEN  = \"Net Zero 2050\"     # z\n",
    "\n",
    "REQUESTED_REGIONS = [\n",
    "    \"USA\",\"EU-15\",\"Europe non EU\",\"Japan\",\"China\",\"India\",\"South Korea\",\n",
    "    \"Canada\",\"Australia-NZ\",\"Taiwan\",\"Mexico\",\"Russia\",\"Brazil\",\"South Africa\",\"Argentina\"\n",
    "]\n",
    "REGION_MAP = {\"Europe non EU\": \"Europe_Non_EU\", \"Australia-NZ\": \"Australia_NZ\"}\n",
    "\n",
    "# Fixed BAU carbon prices ($/tCO2) — strict coverage for MAIN run\n",
    "REGIONAL_BAU_FIXED = {\n",
    "    \"USA\": 23.0, \"EU-15\": 70.0, \"Europe_Non_EU\": 60.0, \"Japan\": 4.0,\n",
    "    \"China\": 11.8, \"India\": 2.0, \"South Korea\": 6.0, \"Canada\": 66.0,\n",
    "    \"Australia_NZ\": 26.0, \"Taiwan\": 9.0, \"Mexico\": 3.9, \"Russia\": 2.0,\n",
    "    \"Brazil\": 2.0, \"South Africa\": 12.8, \"Argentina\": 5.3,\n",
    "}\n",
    "\n",
    "HORIZONS = [2030, 2050]\n",
    "T0_ANCHOR = 2020\n",
    "DISCOUNT_RATES_MAIN = [0.02, 0.00]  # main: r=2% and r=0%\n",
    "DISCOUNT_RATES_20   = [0.02]        # BAU=$20 run: r=2% only\n",
    "\n",
    "# ---- NGFS sector names & order (10 columns) ----\n",
    "SECTOR_ORDER_FIXED = [\n",
    "    \"Supply\",\"Other Energy Supply\",\"Electricity\",\"Industry\",\"Other Industry\",\n",
    "    \"Chemicals\",\"Cement\",\"Transportation\",\"AFOLU\",\"Other\",\n",
    "]\n",
    "SUPPLY_COMPONENTS = [\"Electricity\", \"Other Energy Supply\"]\n",
    "\n",
    "# --------------------------- HELPERS ---------------------------\n",
    "def read_sheet(path, sheetname=\"data\"):\n",
    "    if not os.path.exists(path): raise FileNotFoundError(path)\n",
    "    xls = pd.ExcelFile(path)\n",
    "    if sheetname not in xls.sheet_names: raise ValueError(f\"'{sheetname}' not in {xls.sheet_names}\")\n",
    "    return pd.read_excel(xls, sheet_name=sheetname)\n",
    "\n",
    "def longify_years(df, id_vars):\n",
    "    year_cols = [c for c in df.columns if str(c).isdigit()]\n",
    "    out = df.melt(id_vars=id_vars, value_vars=year_cols, var_name=\"Year\", value_name=\"Value\")\n",
    "    out[\"Year\"] = out[\"Year\"].astype(int)\n",
    "    return out.dropna(subset=[\"Value\"])\n",
    "\n",
    "def filter_kyoto(df_long):\n",
    "    return df_long[df_long[\"Variable\"].astype(str).str.startswith(\"Emissions|Kyoto Gases|\")].copy()\n",
    "\n",
    "_CANON = {\n",
    "    \"supply\":\"Supply\",\"other energy supply\":\"Other Energy Supply\",\n",
    "    \"electricity\":\"Electricity\",\"power\":\"Electricity\",\n",
    "    \"industry\":\"Industry\",\"other industry\":\"Other Industry\",\n",
    "    \"chemicals\":\"Chemicals\",\"cement\":\"Cement\",\n",
    "    \"transportation\":\"Transportation\",\"transport\":\"Transportation\",\n",
    "    \"afolu\":\"AFOLU\",\"other\":\"Other\",\n",
    "}\n",
    "def ngfs_sector(variable: str) -> str:\n",
    "    last = str(variable).split(\"|\")[-1].strip().lower()\n",
    "    return _CANON.get(last, \"Other\")\n",
    "\n",
    "def resolve_regions(req, rmap, available):\n",
    "    mapped  = [rmap.get(r, r) for r in req]\n",
    "    present = [r for r in mapped if r in available]\n",
    "    reverse = {rmap.get(k, k): k for k in req}\n",
    "    return present, reverse\n",
    "\n",
    "def discount_factors(years, r, t0=T0_ANCHOR):\n",
    "    years = np.asarray(years, dtype=int)\n",
    "    return pd.Series((1.0 + r)**(-(years - t0)), index=years)\n",
    "\n",
    "def per_heatmap_vmax(matrix, p=97):\n",
    "    vals = matrix.values.ravel().astype(float)\n",
    "    vals = vals[np.isfinite(vals)]\n",
    "    return max(np.nanpercentile(vals, p), 1e-12) if vals.size else 1.0\n",
    "\n",
    "def slugify(s: str) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9._-]+\", \"_\", s).strip(\"_\")\n",
    "\n",
    "# ---------- NEW: standardized export path helpers (exports only) ----------\n",
    "def std_paths(horizon_end: int, r_disc: float, mode: str):\n",
    "    \"\"\"Return standardized data/png paths for Streamlit.\n",
    "       mode ∈ {\"eq9_regional\", \"eq9_bau20\"}.\n",
    "    \"\"\"\n",
    "    horizon_str = f\"2020-{horizon_end}\"\n",
    "    rtag = f\"r{int(round(r_disc*100))}\"  # r2 or r0\n",
    "    base = STD_ROOT / horizon_str / mode / rtag\n",
    "    data_dir = base / \"data\"\n",
    "    png_dir  = base / \"png\"\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    png_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return {\n",
    "        \"data_wide\": data_dir / \"heatmap_data.csv\",\n",
    "        \"data_long\": data_dir / \"heatmap_data_long.csv\",\n",
    "        \"png\":       png_dir  / \"heatmap.png\",\n",
    "    }\n",
    "\n",
    "# --------------------------- LOAD DATA ---------------------------\n",
    "em_raw = read_sheet(EMISSIONS_XLSX, \"data\")\n",
    "em_raw[\"Region\"] = em_raw[\"Region\"].astype(str).str.split(\"|\").str[-1]\n",
    "em_long = longify_years(em_raw, [\"Model\",\"Scenario\",\"Region\",\"Variable\",\"Unit\"])\n",
    "em_long = filter_kyoto(em_long)\n",
    "\n",
    "pr_raw = read_sheet(PRICES_XLSX, \"data\")\n",
    "pr_raw[\"Region\"] = pr_raw[\"Region\"].astype(str).str.split(\"|\").str[-1]\n",
    "pr_long = longify_years(pr_raw, [\"Model\",\"Scenario\",\"Region\",\"Variable\",\"Unit\"])\n",
    "\n",
    "# Regions intersection & order\n",
    "avail_regions = set(em_long[\"Region\"].unique()) & set(pr_long[\"Region\"].unique())\n",
    "regions_order, reverse = resolve_regions(REQUESTED_REGIONS, REGION_MAP, avail_regions)\n",
    "em_long = em_long[em_long[\"Region\"].isin(regions_order)].copy()\n",
    "pr_long = pr_long[pr_long[\"Region\"].isin(regions_order)].copy()\n",
    "\n",
    "# Strict BAU fixed-price coverage for MAIN run\n",
    "missing_bau = [r for r in regions_order if r not in REGIONAL_BAU_FIXED]\n",
    "if missing_bau:\n",
    "    raise ValueError(f\"Missing BAU fixed price for regions: {missing_bau}\")\n",
    "nonpos_bau = [r for r,v in REGIONAL_BAU_FIXED.items() if r in regions_order and (v is None or v <= 0)]\n",
    "if nonpos_bau:\n",
    "    raise ValueError(f\"Non-positive BAU fixed price for regions: {nonpos_bau}\")\n",
    "\n",
    "# --------------------------- PREP SERIES ---------------------------\n",
    "def pivot_emissions(df, scenario, year_max):\n",
    "    d = df[(df[\"Scenario\"]==scenario) & (df[\"Year\"]<=year_max)].copy()\n",
    "    d[\"Sector\"] = d[\"Variable\"].apply(ngfs_sector)\n",
    "    return d.rename(columns={\"Value\":\"E\"})\n",
    "\n",
    "def nz_prices_region(df, year_max):\n",
    "    d = df[(df[\"Scenario\"]==NZ_SCEN) & (df[\"Year\"]<=year_max) &\n",
    "           (df[\"Variable\"].astype(str).str.fullmatch(r\"Price\\|Carbon\"))][[\"Region\",\"Year\",\"Value\"]]\n",
    "    if d.empty:\n",
    "        raise ValueError(\"No region-level NZ 'Price|Carbon' found in PRICES_XLSX.\")\n",
    "    return d.rename(columns={\"Value\":\"Pz_reg\"})\n",
    "\n",
    "# --------------------------- METRIC (Eq. 9) ---------------------------\n",
    "def compute_eq9_matrix(H, r_disc, bau_price_spec):\n",
    "    \"\"\"\n",
    "    bau_price_spec: dict {Region -> price} or a float (constant for all regions).\n",
    "    Returns matrix (Region x Sector) of Eq9_Ctilde.\n",
    "    \"\"\"\n",
    "    Eb = pivot_emissions(em_long, BAU_SCEN, H).rename(columns={\"E\":\"E_b\"})\n",
    "    Ez = pivot_emissions(em_long, NZ_SCEN, H).rename(columns={\"E\":\"E_z\"})\n",
    "    key = [\"Region\",\"Variable\",\"Unit\",\"Year\",\"Sector\"]\n",
    "    m = Eb[key+[\"E_b\"]].merge(Ez[key+[\"E_z\"]], on=key, how=\"inner\")\n",
    "\n",
    "    # NZ region-level prices\n",
    "    Pz = nz_prices_region(pr_long, H)\n",
    "    m = m.merge(Pz, on=[\"Region\",\"Year\"], how=\"left\")\n",
    "\n",
    "    # Fixed BAU price per region\n",
    "    if isinstance(bau_price_spec, dict):\n",
    "        m[\"Pb_den\"] = m[\"Region\"].map(bau_price_spec).astype(float)\n",
    "        if m[\"Pb_den\"].isna().any():\n",
    "            bad = m.loc[m[\"Pb_den\"].isna(),\"Region\"].unique().tolist()\n",
    "            raise ValueError(f\"BAU fixed price unexpectedly missing after mapping for: {bad}\")\n",
    "    else:\n",
    "        m[\"Pb_den\"] = float(bau_price_spec)\n",
    "\n",
    "    # (E_b - E_z)_+\n",
    "    m[\"Excess_pos\"] = np.clip(m[\"E_b\"] - m[\"E_z\"], 0.0, None)\n",
    "\n",
    "    # Discount\n",
    "    years = sorted(m[\"Year\"].unique())\n",
    "    D = discount_factors(years, r=r_disc, t0=T0_ANCHOR)\n",
    "    m = m.merge(D.rename(\"D\").rename_axis(\"Year\").reset_index(), on=\"Year\", how=\"left\")\n",
    "\n",
    "    # Per-row contributions\n",
    "    m[\"Num_t\"] = m[\"D\"] * m[\"Pz_reg\"] * m[\"Excess_pos\"]\n",
    "    m[\"Den_t\"] = m[\"D\"] * m[\"Pb_den\"] * m[\"E_b\"]\n",
    "\n",
    "    # Group by (Region, Sector)\n",
    "    grp = (m.groupby([\"Region\",\"Sector\"], as_index=False)[[\"Num_t\",\"Den_t\"]].sum())\n",
    "\n",
    "    # Synthesize 'Supply' if components exist\n",
    "    present = set(grp[\"Sector\"].unique())\n",
    "    if (\"Supply\" not in present) and all(s in present for s in SUPPLY_COMPONENTS):\n",
    "        supply = (grp[grp[\"Sector\"].isin(SUPPLY_COMPONENTS)]\n",
    "                  .groupby(\"Region\", as_index=False)[[\"Num_t\",\"Den_t\"]].sum())\n",
    "        supply[\"Sector\"] = \"Supply\"\n",
    "        grp = pd.concat([grp, supply], ignore_index=True)\n",
    "\n",
    "    # Final ratio\n",
    "    grp[\"Eq9_Ctilde\"] = np.where(grp[\"Den_t\"] > 0, grp[\"Num_t\"]/grp[\"Den_t\"], np.nan)\n",
    "\n",
    "    # Pivot to matrix with fixed NGFS order\n",
    "    mat = grp.pivot(index=\"Region\", columns=\"Sector\", values=\"Eq9_Ctilde\")\n",
    "    mat = mat.reindex(index=regions_order)\n",
    "    for col in SECTOR_ORDER_FIXED:\n",
    "        if col not in mat.columns:\n",
    "            mat[col] = np.nan\n",
    "    mat = mat[SECTOR_ORDER_FIXED]\n",
    "    return mat\n",
    "\n",
    "# --------------------------- PLOTTING ---------------------------\n",
    "def plot_heatmap(mat, title, rotate_xticks=True):\n",
    "    import seaborn as sns\n",
    "    fig, ax = plt.subplots(figsize=(0.5*max(8, mat.shape[1]) + 6,\n",
    "                                    0.45*max(6, mat.shape[0]) + 3))\n",
    "    cm = plt.get_cmap(\"RdYlGn_r\").copy()\n",
    "    try: cm.set_bad('#e6e6e6')\n",
    "    except: pass\n",
    "    vmax = per_heatmap_vmax(mat, p=97)\n",
    "    sns.heatmap(mat.clip(lower=0, upper=vmax), ax=ax, cmap=cm,\n",
    "                vmin=0, vmax=vmax, mask=np.isnan(mat.values),\n",
    "                linewidths=0.2, linecolor='white', cbar=False)\n",
    "    if rotate_xticks:\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                           rotation_mode=\"anchor\", fontsize=9)\n",
    "    ax.set_title(title, fontsize=11); ax.set_xlabel(\"Sector\"); ax.set_ylabel(\"Region\")\n",
    "    im = ax.collections[0]\n",
    "    cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.02)\n",
    "    cbar.set_label(r\"$\\tilde{C}^{z|b}$\")\n",
    "    ax.text(0.99, 1.02, f\"p97≈{vmax:.2g}\", transform=ax.transAxes,\n",
    "            ha=\"right\", va=\"bottom\", fontsize=8, color=\"#555\")\n",
    "    fig.tight_layout(); fig.subplots_adjust(bottom=0.18)\n",
    "    return fig\n",
    "\n",
    "# --------------------------- UTIL: RUN + SAVE ---------------------------\n",
    "def export_standardized_assets(mat: pd.DataFrame, fig, H: int, r_disc: float, mode: str):\n",
    "    \"\"\"Save standardized PNG + CSVs for Streamlit; keep math unchanged.\"\"\"\n",
    "    paths = std_paths(horizon_end=H, r_disc=r_disc, mode=mode)\n",
    "\n",
    "    # 1) PNG\n",
    "    fig.savefig(paths[\"png\"], dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    # 2) Wide CSV (Region×Sector matrix)\n",
    "    wide = mat.copy()\n",
    "    wide.index.name = \"Region\"\n",
    "    wide.to_csv(paths[\"data_wide\"])\n",
    "\n",
    "    # 3) Long CSV\n",
    "    long_df = (wide.reset_index()\n",
    "                    .melt(id_vars=\"Region\", var_name=\"Sector\", value_name=\"Eq9_Ctilde\"))\n",
    "    long_df.to_csv(paths[\"data_long\"], index=False)\n",
    "\n",
    "def run_and_export(pdf_path, png_dir, discount_rates, bau_price_spec, title_suffix, mode_key: str):\n",
    "    \"\"\"\n",
    "    mode_key: 'eq9_regional' for dict prices; 'eq9_bau20' for constant price.\n",
    "    \"\"\"\n",
    "    os.makedirs(png_dir, exist_ok=True)\n",
    "    with PdfPages(pdf_path) as pp:\n",
    "        # Cover page (unchanged content)\n",
    "        fig = plt.figure(figsize=(11, 8.5)); plt.axis(\"off\")\n",
    "        bullets = [\n",
    "            r\"Eq. (9): $\\tilde{C}^{z|b} = \\frac{\\sum_t D_t P^z_{r,t}(E^b-E^z)_+}{\\sum_t D_t P^{b,\\mathrm{fixed}}_r E^b}$\",\n",
    "            \"NZ price: region-level Price|Carbon from PRICES_XLSX.\",\n",
    "            f\"Sectors (NGFS): \" + \", \".join(SECTOR_ORDER_FIXED),\n",
    "            f\"Horizons: 2020–2030, 2020–2050. Discount rates: \" +\n",
    "            \", \".join([f\"{int(r*100)}%\" for r in discount_rates]) + f\" (t0 = {T0_ANCHOR}).\",\n",
    "        ]\n",
    "        if isinstance(bau_price_spec, dict):\n",
    "            bullets.insert(2, \"BAU prices: region-specific fixed values.\")\n",
    "        else:\n",
    "            bullets.insert(2, f\"BAU price: fixed = ${float(bau_price_spec):g}/tCO₂ for all regions.\")\n",
    "        y = 0.92\n",
    "        plt.text(0.05, y, f\"Transition Cost — Eq. (9) Heatmaps {title_suffix}\",\n",
    "                 fontsize=16, weight=\"bold\"); y -= 0.06\n",
    "        for b in bullets:\n",
    "            plt.text(0.05, y, u\"\\u2022 \" + b, fontsize=11); y -= 0.035\n",
    "        plt.text(0.05, 0.06,\n",
    "                 f\"Inputs: {os.path.basename(EMISSIONS_XLSX)}, {os.path.basename(PRICES_XLSX)}\",\n",
    "                 fontsize=9, color=\"#555\")\n",
    "        pp.savefig(fig); plt.close(fig)\n",
    "\n",
    "        # Pages + standardized exports\n",
    "        for r_disc in discount_rates:\n",
    "            for H in HORIZONS:\n",
    "                mat = compute_eq9_matrix(H, r_disc, bau_price_spec)\n",
    "                ttl = f\"Eq. (9) — Normalized Transition Cost, 2020–{H} (r={int(r_disc*100)}%) {title_suffix}\"\n",
    "                fig = plot_heatmap(mat, ttl, rotate_xticks=True)\n",
    "\n",
    "                # Legacy PNG (unchanged)\n",
    "                fn = f\"Eq9_{int(r_disc*100)}pct_{H}{'_BAU20' if not isinstance(bau_price_spec, dict) else ''}.png\"\n",
    "                fig.savefig(os.path.join(png_dir, slugify(fn)), dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "                # NEW standardized exports for Streamlit (PNG + CSVs)\n",
    "                export_standardized_assets(mat, fig, H=H, r_disc=r_disc, mode=mode_key)\n",
    "\n",
    "                # Add to legacy PDF\n",
    "                pp.savefig(fig)\n",
    "                plt.close(fig)\n",
    "\n",
    "    print(f\"[OK] PDF -> {pdf_path}\\n[OK] PNGs -> {png_dir}\")\n",
    "    print(f\"[OK] Standardized exports -> {STD_ROOT}\")\n",
    "\n",
    "# --------------------------- RUN BOTH SCENARIOS ---------------------------\n",
    "# 1) Main: regional BAU prices, r∈{2%,0%}\n",
    "run_and_export(\n",
    "    pdf_path=PDF_OUT_MAIN,\n",
    "    png_dir=PNG_DIR_MAIN,\n",
    "    discount_rates=DISCOUNT_RATES_MAIN,\n",
    "    bau_price_spec=REGIONAL_BAU_FIXED,\n",
    "    title_suffix=\"(Regional BAU fixed prices)\",\n",
    "    mode_key=\"eq9_regional\",\n",
    ")\n",
    "\n",
    "# 2) Special: BAU fixed = $20/tCO2 for all regions, r=2%\n",
    "run_and_export(\n",
    "    pdf_path=PDF_OUT_20,\n",
    "    png_dir=PNG_DIR_20,\n",
    "    discount_rates=DISCOUNT_RATES_20,\n",
    "    bau_price_spec=20.0,\n",
    "    title_suffix=\"(BAU fixed = $20/tCO₂)\",\n",
    "    mode_key=\"eq9_bau20\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99d4e928-20bf-4c6d-970d-8e4db78d0c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] PDF written -> /Users/noenotter/Documents/Summer_intern/outputs/NGFS_Heatmaps.pdf\n",
      "[OK] PNGs in -> /Users/noenotter/Documents/Summer_intern/outputs/NGFS_Heatmaps_png\n",
      "[OK] Standardized PM/BO/AS -> /Users/noenotter/Documents/Summer_intern/outputs/transition/2020-{2030,2050}/{pm,bo,as}/{data,png}/\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Path Misalignment (A), Budget Overshoot (Ω), Abatement Share (AS)\n",
    "# — calculations/plots unchanged —\n",
    "# + standardized exports for Streamlit (PNG + CSV wide + CSV long)\n",
    "# ==========================================================\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "ROOT = os.path.expanduser(\"~/Documents/Summer_intern\")\n",
    "EMISSIONS_XLSX = os.path.join(ROOT, \"NGFS_GCAM_Carbon_Emissions_Sectors.xlsx\")\n",
    "\n",
    "OUTDIR = os.path.join(ROOT, \"outputs\"); os.makedirs(OUTDIR, exist_ok=True)\n",
    "PDF_PATH = os.path.join(OUTDIR, \"NGFS_Heatmaps.pdf\")\n",
    "PNG_DIR  = os.path.join(OUTDIR, \"NGFS_Heatmaps_png\"); os.makedirs(PNG_DIR, exist_ok=True)\n",
    "\n",
    "# NEW standardized base (what Streamlit app v3 reads)\n",
    "STD_TRANS_ROOT = Path(ROOT) / \"outputs\" / \"transition\"\n",
    "\n",
    "BAU_SCEN = \"Current Policies\"\n",
    "NZ_SCEN  = \"Net Zero 2050\"\n",
    "\n",
    "HORIZONS   = [2030, 2050]                 # for Ω and AS\n",
    "A_WINDOWS  = [(2020, 2030), (2020, 2050)] # for A\n",
    "\n",
    "# Fixed rows (regions)\n",
    "REQUESTED_REGIONS = [\n",
    "    \"USA\",\"EU-15\",\"Europe non EU\",\"Japan\",\"China\",\"India\",\"South Korea\",\n",
    "    \"Canada\",\"Australia-NZ\",\"Taiwan\",\"Mexico\",\"Russia\",\"Brazil\",\"South Africa\",\"Argentina\"\n",
    "]\n",
    "REGION_MAP = {\"Europe non EU\": \"Europe_Non_EU\", \"Australia-NZ\": \"Australia_NZ\"}\n",
    "\n",
    "# Fixed columns (NGFS exact sector names)\n",
    "SECTOR_ORDER_FIXED = [\n",
    "    \"Supply\",\"Other Energy Supply\",\"Electricity\",\"Steel\",\"Cement\",\"Chemicals\",\n",
    "    \"Other Industry\",\"Industry\",\"Transportation\",\"AFOLU\",\"Other\",\n",
    "]\n",
    "SUPPLY_COMPONENTS = [\"Electricity\", \"Other Energy Supply\"]\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def read_emissions_xlsx(path: str) -> pd.DataFrame:\n",
    "    if not os.path.exists(path): raise FileNotFoundError(path)\n",
    "    xls = pd.ExcelFile(path)\n",
    "    if \"data\" not in xls.sheet_names: raise ValueError(f\"'data' not in {xls.sheet_names}\")\n",
    "    df = pd.read_excel(xls, sheet_name=\"data\")\n",
    "    df[\"Region\"] = df[\"Region\"].astype(str).str.split(\"|\").str[-1]\n",
    "    return df\n",
    "\n",
    "def year_columns(df: pd.DataFrame) -> list:\n",
    "    return [c for c in df.columns if str(c).isdigit()]\n",
    "\n",
    "def longify(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    yrs = year_columns(df)\n",
    "    out = df.melt(\n",
    "        id_vars=[\"Model\",\"Scenario\",\"Region\",\"Variable\",\"Unit\"],\n",
    "        value_vars=yrs, var_name=\"Year\", value_name=\"Value\"\n",
    "    )\n",
    "    out[\"Year\"] = out[\"Year\"].astype(int)\n",
    "    return out.dropna(subset=[\"Value\"])\n",
    "\n",
    "def filter_kyoto(df_long: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df_long[df_long[\"Variable\"].astype(str).str.startswith(\"Emissions|Kyoto Gases|\")].copy()\n",
    "\n",
    "# Map NGFS last-token sector names to our exact labels (case-insensitive)\n",
    "_SECTOR_CANON = {\n",
    "    \"supply\": \"Supply\",\n",
    "    \"other energy supply\": \"Other Energy Supply\",\n",
    "    \"electricity\": \"Electricity\", \"power\": \"Electricity\",\n",
    "    \"steel\": \"Steel\",\n",
    "    \"cement\": \"Cement\",\n",
    "    \"chemicals\": \"Chemicals\",\n",
    "    \"other industry\": \"Other Industry\",\n",
    "    \"industry\": \"Industry\",\n",
    "    \"transportation\": \"Transportation\", \"transport\": \"Transportation\",\n",
    "    \"afolu\": \"AFOLU\",\n",
    "    \"other\": \"Other\",\n",
    "}\n",
    "def map_sector(variable: str) -> str:\n",
    "    last = str(variable).split(\"|\")[-1].strip().lower()\n",
    "    return _SECTOR_CANON.get(last, \"Other\")\n",
    "\n",
    "def resolve_regions(req: list, region_map: dict, available: set):\n",
    "    mapped = [region_map.get(r, r) for r in req]\n",
    "    present = [r for r in mapped if r in available]\n",
    "    reverse = {region_map.get(k, k): k for k in req}\n",
    "    return present, reverse\n",
    "\n",
    "def ensure_sector_columns(mat: pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in SECTOR_ORDER_FIXED:\n",
    "        if col not in mat.columns: mat[col] = np.nan\n",
    "    return mat[SECTOR_ORDER_FIXED]\n",
    "\n",
    "def slugify(s: str) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9._-]+\", \"_\", s).strip(\"_\")\n",
    "\n",
    "def per_heatmap_vmax(matrix, p=97):\n",
    "    vals = matrix.values.ravel().astype(float)\n",
    "    vals = vals[np.isfinite(vals)]\n",
    "    return max(np.nanpercentile(vals, p), 1e-12) if vals.size else 1.0\n",
    "\n",
    "# ---------- NEW: standardized export helpers ----------\n",
    "def std_paths_transition_metric(horizon_end: int, metric_key: str):\n",
    "    \"\"\"\n",
    "    metric_key in {'pm','bo','as'}.\n",
    "    Returns directories for standardized exports.\n",
    "    \"\"\"\n",
    "    horizon_str = f\"2020-{horizon_end}\"\n",
    "    base = STD_TRANS_ROOT / horizon_str / metric_key\n",
    "    data_dir = base / \"data\"\n",
    "    png_dir  = base / \"png\"\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    png_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return {\n",
    "        \"data_wide\": data_dir / \"heatmap_data.csv\",\n",
    "        \"data_long\": data_dir / \"heatmap_data_long.csv\",\n",
    "        \"png\":       png_dir  / \"heatmap.png\",\n",
    "    }\n",
    "\n",
    "def export_std(mat: pd.DataFrame, fig, horizon_end: int, metric_key: str):\n",
    "    \"\"\"Save standardized PNG + CSVs for Streamlit (PM/BO/AS).\"\"\"\n",
    "    paths = std_paths_transition_metric(horizon_end, metric_key)\n",
    "    # 1) PNG\n",
    "    fig.savefig(paths[\"png\"], dpi=300, bbox_inches=\"tight\")\n",
    "    # 2) Wide CSV\n",
    "    wide = mat.copy()\n",
    "    wide.index.name = \"Region\"\n",
    "    wide.to_csv(paths[\"data_wide\"])\n",
    "    # 3) Long CSV\n",
    "    long_df = (wide.reset_index()\n",
    "                    .melt(id_vars=\"Region\", var_name=\"Sector\", value_name=\"Value\"))\n",
    "    long_df.to_csv(paths[\"data_long\"], index=False)\n",
    "\n",
    "# Plot utility (unchanged style)\n",
    "def plot_heatmap(matrix: pd.DataFrame, title: str, cbar_label: str = \"\", metric: str = None):\n",
    "    import seaborn as sns\n",
    "    fig, ax = plt.subplots(figsize=(0.5*max(8, matrix.shape[1]) + 6,\n",
    "                                    0.45*max(6, matrix.shape[0]) + 3))\n",
    "    cm = plt.get_cmap(\"RdYlGn_r\").copy()\n",
    "    try: cm.set_bad('#e6e6e6')\n",
    "    except: pass\n",
    "    vmax = per_heatmap_vmax(matrix, p=97)\n",
    "    sns.heatmap(matrix.clip(lower=0, upper=vmax), ax=ax, cmap=cm,\n",
    "                vmin=0, vmax=vmax, mask=np.isnan(matrix.values),\n",
    "                linewidths=0.2, linecolor='white', cbar=False)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                       rotation_mode=\"anchor\", fontsize=9)\n",
    "    ax.set_title(title, fontsize=11); ax.set_xlabel(\"Sector\"); ax.set_ylabel(\"Region\")\n",
    "    im = ax.collections[0]\n",
    "    cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.02)\n",
    "    if not cbar_label:\n",
    "        if metric == \"A\":       cbar_label = \"Path misalignment (A)\"\n",
    "        elif metric == \"Omega\": cbar_label = \"Budget overshoot (Ω)\"\n",
    "        elif metric == \"AS\":    cbar_label = \"Abatement share (AS)\"\n",
    "        else:                   cbar_label = \"Value\"\n",
    "    cbar.set_label(cbar_label)\n",
    "    ax.text(0.99, 1.02, f\"p97≈{vmax:.2g}\", transform=ax.transAxes,\n",
    "            ha=\"right\", va=\"bottom\", fontsize=8, color=\"#555\")\n",
    "    fig.tight_layout(); fig.subplots_adjust(bottom=0.18)\n",
    "    return fig\n",
    "\n",
    "# ---------------- Load & prep ----------------\n",
    "raw = read_emissions_xlsx(EMISSIONS_XLSX)\n",
    "df_long = filter_kyoto(longify(raw))\n",
    "\n",
    "# Keep requested regions (intersection, fixed order)\n",
    "avail_regions = set(df_long[\"Region\"].unique())\n",
    "regions_order, reverse_map = resolve_regions(REQUESTED_REGIONS, REGION_MAP, avail_regions)\n",
    "df_long = df_long[df_long[\"Region\"].isin(regions_order)].copy()\n",
    "\n",
    "# Canonical sectors (exact NGFS names)\n",
    "df_long[\"Sector\"] = df_long[\"Variable\"].apply(map_sector)\n",
    "df_long[\"Year\"]   = df_long[\"Year\"].astype(int)\n",
    "\n",
    "# Per-year series\n",
    "def per_year_series(df, scen):\n",
    "    d = df[df[\"Scenario\"]==scen].copy()\n",
    "    s = d.groupby([\"Region\",\"Sector\",\"Year\"], as_index=False)[\"Value\"].sum()\n",
    "    return s.rename(columns={\"Value\": f\"E_{'b' if scen==BAU_SCEN else 'z'}\"})\n",
    "\n",
    "Eb = per_year_series(df_long, BAU_SCEN)\n",
    "Ez = per_year_series(df_long, NZ_SCEN)\n",
    "M  = Eb.merge(Ez, on=[\"Region\",\"Sector\",\"Year\"], how=\"inner\")\n",
    "\n",
    "# If 'Supply' missing but components exist, synthesize it\n",
    "present_sectors = set(M[\"Sector\"].unique())\n",
    "if \"Supply\" not in present_sectors and all(s in present_sectors for s in SUPPLY_COMPONENTS):\n",
    "    sup = (M[M[\"Sector\"].isin(SUPPLY_COMPONENTS)]\n",
    "             .groupby([\"Region\",\"Year\"], as_index=False)[[\"E_b\",\"E_z\"]].sum())\n",
    "    sup[\"Sector\"] = \"Supply\"\n",
    "    M = pd.concat([M, sup], ignore_index=True, sort=False)\n",
    "\n",
    "# ---------------- Build PDF + PNGs + STANDARD EXPORTS ----------------\n",
    "with PdfPages(PDF_PATH) as pp:\n",
    "\n",
    "    # ----- A: Path Misalignment (strict) -----\n",
    "    for (ymin, ymax) in A_WINDOWS:\n",
    "        H = ymax  # horizon end for standardized folder\n",
    "        A = M[(M[\"Year\"]>=ymin) & (M[\"Year\"]<=ymax)].copy()\n",
    "        A = A[(A[\"E_b\"]>0) & (A[\"E_z\"]>0)].copy()\n",
    "        A[\"log_ratio\"] = np.log(A[\"E_b\"] / A[\"E_z\"])\n",
    "        A_sum = (A.groupby([\"Region\",\"Sector\"], as_index=False)[\"log_ratio\"].sum()\n",
    "                   .rename(columns={\"log_ratio\":\"A\"}))\n",
    "        A_mat = A_sum.pivot(index=\"Region\", columns=\"Sector\", values=\"A\").reindex(index=regions_order)\n",
    "        A_mat = ensure_sector_columns(A_mat)\n",
    "\n",
    "        title = f\"Path Misalignment A = Σ ln(E_b/E_z), {ymin}–{ymax}\"\n",
    "        fig = plot_heatmap(A_mat, title, metric=\"A\")\n",
    "        pp.savefig(fig)\n",
    "        # legacy PNG (unchanged)\n",
    "        fig.savefig(os.path.join(PNG_DIR, slugify(f\"A_{ymin}-{ymax}.png\")), dpi=300, bbox_inches=\"tight\")\n",
    "        # NEW standardized export for Streamlit\n",
    "        export_std(A_mat, fig, horizon_end=H, metric_key=\"pm\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    # ----- Ω and AS (strict; per-panel dynamic scaling like A) -----\n",
    "    for H in HORIZONS:\n",
    "        Z = M[M[\"Year\"] <= H].copy()\n",
    "        Z[\"diff_pos\"] = np.clip(Z[\"E_b\"] - Z[\"E_z\"], 0.0, None)\n",
    "\n",
    "        G = (Z.groupby([\"Region\", \"Sector\"], as_index=False)\n",
    "               .agg(Eb_sum=(\"E_b\", \"sum\"),\n",
    "                    Ez_sum=(\"E_z\", \"sum\"),\n",
    "                    diff_sum=(\"diff_pos\", \"sum\")))\n",
    "\n",
    "        # Strict formulas: NaN if denominator <= 0\n",
    "        G[\"Omega\"] = np.where(G[\"Ez_sum\"] > 0, G[\"diff_sum\"] / G[\"Ez_sum\"], np.nan)\n",
    "        G[\"AS\"]    = np.where(G[\"Eb_sum\"] > 0, G[\"diff_sum\"] / G[\"Eb_sum\"], np.nan)\n",
    "\n",
    "        panels = [\n",
    "            (\"Omega\", f\"Budget Overshoot Ω, 2020–{H}\", \"bo\", \"Omega\"),\n",
    "            (\"AS\",    f\"Abatement Share, 2020–{H}\",     \"as\", \"AS\"),\n",
    "        ]\n",
    "\n",
    "        for col, title, mkey, metric in panels:\n",
    "            mat = (G.pivot(index=\"Region\", columns=\"Sector\", values=col)\n",
    "                     .reindex(index=regions_order))\n",
    "            mat = ensure_sector_columns(mat)\n",
    "\n",
    "            fig = plot_heatmap(mat, title, metric=metric)\n",
    "            pp.savefig(fig)\n",
    "            # legacy PNG (unchanged)\n",
    "            fig.savefig(os.path.join(PNG_DIR, slugify(f\"{col}_{H}.png\")), dpi=300, bbox_inches=\"tight\")\n",
    "            # NEW standardized export for Streamlit\n",
    "            export_std(mat, fig, horizon_end=H, metric_key=mkey)\n",
    "            plt.close(fig)\n",
    "\n",
    "print(f\"[OK] PDF written -> {PDF_PATH}\\n[OK] PNGs in -> {PNG_DIR}\")\n",
    "print(f\"[OK] Standardized PM/BO/AS -> {STD_TRANS_ROOT}/2020-{{2030,2050}}/{{pm,bo,as}}/{{data,png}}/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

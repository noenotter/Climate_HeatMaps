{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "861d7d16-44f1-437f-87f6-22e8fdd176e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not locate project root with lib/ and config.yaml",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     cur \u001b[38;5;241m=\u001b[39m cur\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate project root with lib/ and config.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Now safe to import our path helpers\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpaths\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CFG, in_data, in_out, ensure_out_dirs\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not locate project root with lib/ and config.yaml"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Path Misalignment (A), Budget Overshoot (Ω), Abatement Share (AS)\n",
    "# Strict formulas; NGFS sector names preserved.\n",
    "# Horizons: 2030, 2050.  Per-panel p97 scaling for all three.\n",
    "# Also exports each heatmap as a PNG (one image per file).\n",
    "# ==========================================================\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "\n",
    "# --- Portable config (project-relative) ---\n",
    "# ==========================================================\n",
    "# Bootstrap: find project root, import portable paths\n",
    "# ==========================================================\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Start from the current working directory (or file location if available)\n",
    "cur = Path(__file__).resolve().parent if \"__file__\" in globals() else Path.cwd()\n",
    "\n",
    "found = False\n",
    "while cur != cur.parent:  # climb upwards until root\n",
    "    if (cur / \"lib\").exists() and (cur / \"config.yaml\").exists():\n",
    "        sys.path.insert(0, str(cur))\n",
    "        found = True\n",
    "        break\n",
    "    cur = cur.parent\n",
    "\n",
    "if not found:\n",
    "    raise RuntimeError(\"Could not locate project root with lib/ and config.yaml\")\n",
    "\n",
    "# Now safe to import our path helpers\n",
    "from lib.paths import CFG, in_data, in_out, ensure_out_dirs\n",
    "ensure_out_dirs()\n",
    "\n",
    "# Inputs via config.yaml\n",
    "EMISSIONS_XLSX = in_data(CFG[\"default_inputs\"][\"emissions_xlsx\"])\n",
    "\n",
    "# Outputs (always under outputs/)\n",
    "PDF_PATH = in_out(\"pdf/NGFS_Heatmaps.pdf\")\n",
    "PNG_DIR  = in_out(\"png/NGFS_Heatmaps_png\")\n",
    "PNG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root found at: {cur}\")\n",
    "print(f\"Inputs: {EMISSIONS_XLSX}\")\n",
    "print(f\"Outputs: {PDF_PATH}, {PNG_DIR}\")\n",
    "\n",
    "\n",
    "\n",
    "BAU_SCEN = \"Current Policies\"\n",
    "NZ_SCEN  = \"Net Zero 2050\"\n",
    "\n",
    "HORIZONS   = [2030, 2050]                 # for Ω and AS\n",
    "A_WINDOWS  = [(2020, 2030), (2020, 2050)] # for A\n",
    "\n",
    "# Fixed rows (regions)\n",
    "REQUESTED_REGIONS = [\n",
    "    \"USA\",\"EU-15\",\"Europe non EU\",\"Japan\",\"China\",\"India\",\"South Korea\",\n",
    "    \"Canada\",\"Australia-NZ\",\"Taiwan\",\"Mexico\",\"Russia\",\"Brazil\",\"South Africa\",\"Argentina\"\n",
    "]\n",
    "REGION_MAP = {\"Europe non EU\": \"Europe_Non_EU\", \"Australia-NZ\": \"Australia_NZ\"}\n",
    "\n",
    "# Fixed columns (NGFS exact sector names)\n",
    "SECTOR_ORDER_FIXED = [\n",
    "    \"Supply\",\"Other Energy Supply\",\"Electricity\",\"Steel\",\"Cement\",\"Chemicals\",\n",
    "    \"Other Industry\",\"Industry\",\"Transportation\",\"AFOLU\",\"Other\",\n",
    "]\n",
    "SUPPLY_COMPONENTS = [\"Electricity\", \"Other Energy Supply\"]\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def read_emissions_xlsx(path: str) -> pd.DataFrame:\n",
    "    if not os.path.exists(path): raise FileNotFoundError(path)\n",
    "    xls = pd.ExcelFile(path)\n",
    "    if \"data\" not in xls.sheet_names: raise ValueError(f\"'data' not in {xls.sheet_names}\")\n",
    "    df = pd.read_excel(xls, sheet_name=\"data\")\n",
    "    df[\"Region\"] = df[\"Region\"].astype(str).str.split(\"|\").str[-1]\n",
    "    return df\n",
    "\n",
    "def year_columns(df: pd.DataFrame) -> list:\n",
    "    return [c for c in df.columns if str(c).isdigit()]\n",
    "\n",
    "def longify(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    yrs = year_columns(df)\n",
    "    out = df.melt(\n",
    "        id_vars=[\"Model\",\"Scenario\",\"Region\",\"Variable\",\"Unit\"],\n",
    "        value_vars=yrs, var_name=\"Year\", value_name=\"Value\"\n",
    "    )\n",
    "    out[\"Year\"] = out[\"Year\"].astype(int)\n",
    "    return out.dropna(subset=[\"Value\"])\n",
    "\n",
    "def filter_kyoto(df_long: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df_long[df_long[\"Variable\"].astype(str).str.startswith(\"Emissions|Kyoto Gases|\")].copy()\n",
    "\n",
    "# Map NGFS last-token sector names to our exact labels (case-insensitive)\n",
    "_SECTOR_CANON = {\n",
    "    \"supply\": \"Supply\",\n",
    "    \"other energy supply\": \"Other Energy Supply\",\n",
    "    \"electricity\": \"Electricity\", \"power\": \"Electricity\",\n",
    "    \"steel\": \"Steel\",\n",
    "    \"cement\": \"Cement\",\n",
    "    \"chemicals\": \"Chemicals\",\n",
    "    \"other industry\": \"Other Industry\",\n",
    "    \"industry\": \"Industry\",\n",
    "    \"transportation\": \"Transportation\", \"transport\": \"Transportation\",\n",
    "    \"afolu\": \"AFOLU\",\n",
    "    \"other\": \"Other\",\n",
    "}\n",
    "def map_sector(variable: str) -> str:\n",
    "    last = str(variable).split(\"|\")[-1].strip().lower()\n",
    "    return _SECTOR_CANON.get(last, \"Other\")\n",
    "\n",
    "def resolve_regions(req: list, region_map: dict, available: set):\n",
    "    mapped = [region_map.get(r, r) for r in req]\n",
    "    present = [r for r in mapped if r in available]\n",
    "    reverse = {region_map.get(k, k): k for k in req}\n",
    "    return present, reverse\n",
    "\n",
    "def ensure_sector_columns(mat: pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in SECTOR_ORDER_FIXED:\n",
    "        if col not in mat.columns: mat[col] = np.nan\n",
    "    return mat[SECTOR_ORDER_FIXED]\n",
    "\n",
    "def slugify(s: str) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9._-]+\", \"_\", s).strip(\"_\")\n",
    "\n",
    "def plot_heatmap(\n",
    "    matrix: pd.DataFrame,\n",
    "    title: str,\n",
    "    vmin=None,\n",
    "    vmax=None,\n",
    "    cbar_label: str = \"\",\n",
    "    metric: str = None,               # 'A', 'Omega', or 'AS' for auto labels\n",
    "    rotate_xticks: bool = True,\n",
    "    xtick_rotation: float = 45.0,     # diagonal labels\n",
    "    xtick_fontsize: int = 9,\n",
    "    annotate_scale: bool = True,      # show the scale max note\n",
    "):\n",
    "    import seaborn as sns\n",
    "    fig = plt.figure(figsize=(0.5*len(matrix.columns)+6, 0.45*len(matrix.index)+3))\n",
    "    cm = plt.get_cmap(\"RdYlGn_r\").copy()\n",
    "    try: cm.set_bad('#e6e6e6')\n",
    "    except: pass\n",
    "\n",
    "    vals = matrix.values.ravel().astype(float)\n",
    "    vals = vals[np.isfinite(vals)]\n",
    "    used_vmax = vmax if vmax is not None else (max(np.nanpercentile(vals, 97), 1e-12) if vals.size else 1.0)\n",
    "    used_vmin = 0.0 if vmin is None else vmin\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "        matrix.clip(lower=used_vmin, upper=used_vmax),\n",
    "        cmap=cm, vmin=used_vmin, vmax=used_vmax,\n",
    "        mask=np.isnan(matrix.values),\n",
    "        linewidths=0.2, linecolor='white', cbar=True\n",
    "    )\n",
    "\n",
    "    # Informative colorbar label\n",
    "    if not cbar_label:\n",
    "        if metric == \"A\":\n",
    "            cbar_label = r\"Path misalignment  $A=\\sum_t \\ln(E_b/E_z)$\"\n",
    "        elif metric == \"Omega\":\n",
    "            cbar_label = r\"Budget overshoot  $\\Omega=\\frac{\\text{excess}}{\\text{NZ budget}}$\"\n",
    "        elif metric == \"AS\":\n",
    "            cbar_label = r\"Abatement share  $AS=\\frac{\\text{excess}}{\\text{BAU budget}}$\"\n",
    "        else:\n",
    "            cbar_label = \"Value\"\n",
    "\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.set_label(cbar_label, rotation=90)\n",
    "\n",
    "    # Diagonal sector labels for readability\n",
    "    if rotate_xticks:\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=xtick_rotation,\n",
    "                           ha=\"right\", rotation_mode=\"anchor\", fontsize=xtick_fontsize)\n",
    "\n",
    "    ax.set_title(title); ax.set_xlabel(\"Sector\"); ax.set_ylabel(\"Region\")\n",
    "\n",
    "    # Clearer scale note\n",
    "    if annotate_scale:\n",
    "        ax.text(0.99, 1.02, f\"Color scale max = p97 ≈ {used_vmax:.2g}\",\n",
    "                transform=ax.transAxes, ha=\"right\", va=\"bottom\", fontsize=8, color=\"#555\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    # leave room for rotated labels\n",
    "    fig.subplots_adjust(bottom=0.18)\n",
    "    return fig\n",
    "\n",
    "# ---------------- Load & prep ----------------\n",
    "raw = read_emissions_xlsx(EMISSIONS_XLSX)\n",
    "df_long = filter_kyoto(longify(raw))\n",
    "\n",
    "# Keep requested regions (intersection, fixed order)\n",
    "avail_regions = set(df_long[\"Region\"].unique())\n",
    "regions_order, reverse_map = resolve_regions(REQUESTED_REGIONS, REGION_MAP, avail_regions)\n",
    "df_long = df_long[df_long[\"Region\"].isin(regions_order)].copy()\n",
    "\n",
    "# Canonical sectors (exact NGFS names)\n",
    "df_long[\"Sector\"] = df_long[\"Variable\"].apply(map_sector)\n",
    "df_long[\"Year\"]   = df_long[\"Year\"].astype(int)\n",
    "\n",
    "# Per-year series\n",
    "def per_year_series(df, scen):\n",
    "    d = df[df[\"Scenario\"]==scen].copy()\n",
    "    s = d.groupby([\"Region\",\"Sector\",\"Year\"], as_index=False)[\"Value\"].sum()\n",
    "    return s.rename(columns={\"Value\": f\"E_{'b' if scen==BAU_SCEN else 'z'}\"})\n",
    "\n",
    "Eb = per_year_series(df_long, BAU_SCEN)\n",
    "Ez = per_year_series(df_long, NZ_SCEN)\n",
    "M  = Eb.merge(Ez, on=[\"Region\",\"Sector\",\"Year\"], how=\"inner\")\n",
    "\n",
    "# If 'Supply' is missing but the two components exist, synthesize it\n",
    "present_sectors = set(M[\"Sector\"].unique())\n",
    "if \"Supply\" not in present_sectors and all(s in present_sectors for s in SUPPLY_COMPONENTS):\n",
    "    sup = (M[M[\"Sector\"].isin(SUPPLY_COMPONENTS)]\n",
    "             .groupby([\"Region\",\"Year\"], as_index=False)[[\"E_b\",\"E_z\"]].sum())\n",
    "    sup[\"Sector\"] = \"Supply\"\n",
    "    M = pd.concat([M, sup], ignore_index=True, sort=False)\n",
    "\n",
    "# ---------------- Build PDF + PNGs ----------------\n",
    "with PdfPages(PDF_PATH) as pp:\n",
    "\n",
    "    # ----- A: Path Misalignment (strict) -----\n",
    "    for (ymin, ymax) in A_WINDOWS:\n",
    "        A = M[(M[\"Year\"]>=ymin) & (M[\"Year\"]<=ymax)].copy()\n",
    "        A = A[(A[\"E_b\"]>0) & (A[\"E_z\"]>0)].copy()\n",
    "        A[\"log_ratio\"] = np.log(A[\"E_b\"] / A[\"E_z\"])\n",
    "        A_sum = (A.groupby([\"Region\",\"Sector\"], as_index=False)[\"log_ratio\"].sum()\n",
    "                   .rename(columns={\"log_ratio\":\"A\"}))\n",
    "        A_mat = A_sum.pivot(index=\"Region\", columns=\"Sector\", values=\"A\").reindex(index=regions_order)\n",
    "        A_mat = ensure_sector_columns(A_mat)\n",
    "\n",
    "        title = f\"Path Misalignment A = Σ ln(E_b/E_z), {ymin}–{ymax}\"\n",
    "        fig = plot_heatmap(A_mat, title, vmin=0, vmax=None, metric=\"A\")\n",
    "        pp.savefig(fig)\n",
    "        fig.savefig(os.path.join(PNG_DIR, slugify(f\"A_{ymin}-{ymax}.png\")), dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    # ----- Ω and AS (strict; per-panel dynamic scaling like A) -----\n",
    "    for H in HORIZONS:\n",
    "        Z = M[M[\"Year\"] <= H].copy()\n",
    "        Z[\"diff_pos\"] = np.clip(Z[\"E_b\"] - Z[\"E_z\"], 0.0, None)\n",
    "\n",
    "        G = (Z.groupby([\"Region\", \"Sector\"], as_index=False)\n",
    "               .agg(Eb_sum=(\"E_b\", \"sum\"),\n",
    "                    Ez_sum=(\"E_z\", \"sum\"),\n",
    "                    diff_sum=(\"diff_pos\", \"sum\")))\n",
    "\n",
    "        # Strict formulas: NaN if denominator <= 0\n",
    "        G[\"Omega\"] = np.where(G[\"Ez_sum\"] > 0, G[\"diff_sum\"] / G[\"Ez_sum\"], np.nan)\n",
    "        G[\"AS\"]    = np.where(G[\"Eb_sum\"] > 0, G[\"diff_sum\"] / G[\"Eb_sum\"], np.nan)\n",
    "\n",
    "        panels = [\n",
    "            (\"Omega\", f\"Budget Overshoot Ω, 2020–{H}\", None, \"Omega\"),\n",
    "            (\"AS\",    f\"Abatement Share, 2020–{H}\",     None, \"AS\"),\n",
    "        ]\n",
    "\n",
    "        for col, title, vmax, metric in panels:\n",
    "            mat = (G.pivot(index=\"Region\", columns=\"Sector\", values=col)\n",
    "                     .reindex(index=regions_order))\n",
    "            mat = ensure_sector_columns(mat)\n",
    "\n",
    "            fig = plot_heatmap(mat, title, vmin=0, vmax=vmax, metric=metric)\n",
    "            pp.savefig(fig)\n",
    "            fn = f\"{col}_{H}.png\"   # e.g., Omega_2030.png, AS_2050.png\n",
    "            fig.savefig(os.path.join(PNG_DIR, slugify(fn)), dpi=300, bbox_inches=\"tight\")\n",
    "            plt.close(fig)\n",
    "\n",
    "print(f\"[OK] PDF written -> {PDF_PATH}\\n[OK] PNGs in -> {PNG_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69998dc3-89d2-496d-aa8f-6f02563246ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] PDF -> /Users/noenotter/Documents/Summer_intern/outputs/NGFS_Heatmaps_Transition_Cost.pdf\n",
      "[OK] PNGs -> /Users/noenotter/Documents/Summer_intern/outputs/NGFS_Eq9_png\n",
      "[OK] PDF -> /Users/noenotter/Documents/Summer_intern/outputs/NGFS_Heatmaps_Transition_Cost_BAU20_r2pct.pdf\n",
      "[OK] PNGs -> /Users/noenotter/Documents/Summer_intern/outputs/NGFS_Eq9_BAU20_r2pct_png\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Eq. (9) — BAU-normalized transition cost with fixed BAU prices\n",
    "# - Main run: region-specific fixed BAU prices (your table), r ∈ {2%, 0%}, H ∈ {2030, 2050}\n",
    "# - Extra run: BAU fixed = $20/tCO2 for all regions, r = 2% only, H ∈ {2030, 2050}\n",
    "# Exports: one PDF per run + one PNG per heatmap with clear names.\n",
    "# NGFS sector names aligned: Supply / Other Energy Supply / ...\n",
    "# ==========================================================\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# --------------------------- CONFIG ---------------------------\n",
    "# --- Portable config (project-relative) ---\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# make lib/ available\n",
    "cur = Path.cwd()\n",
    "while cur != cur.parent and not (cur / \"lib\").exists():\n",
    "    cur = cur.parent\n",
    "sys.path.insert(0, str(cur))\n",
    "\n",
    "from lib.paths import CFG, in_data, in_out, ensure_out_dirs\n",
    "ensure_out_dirs()\n",
    "\n",
    "# Inputs via config.yaml (no hard-coded names)\n",
    "EMISSIONS_XLSX = in_data(CFG[\"default_inputs\"][\"emissions_xlsx\"])\n",
    "PRICES_XLSX    = in_data(CFG[\"default_inputs\"][\"prices_xlsx\"])\n",
    "\n",
    "# Outputs under outputs/\n",
    "PDF_OUT_MAIN = in_out(\"pdf/NGFS_Heatmaps_Transition_Cost.pdf\")\n",
    "PNG_DIR_MAIN = in_out(\"png/NGFS_Eq9_png\"); os.makedirs(PNG_DIR_MAIN, exist_ok=True)\n",
    "\n",
    "PDF_OUT_20   = in_out(\"pdf/NGFS_Heatmaps_Transition_Cost_BAU20_r2pct.pdf\")\n",
    "PNG_DIR_20   = in_out(\"png/NGFS_Eq9_BAU20_r2pct_png\"); os.makedirs(PNG_DIR_20, exist_ok=True)\n",
    "\n",
    "\n",
    "BAU_SCEN = \"Current Policies\"   # b\n",
    "NZ_SCEN  = \"Net Zero 2050\"      # z\n",
    "\n",
    "REQUESTED_REGIONS = [\n",
    "    \"USA\",\"EU-15\",\"Europe non EU\",\"Japan\",\"China\",\"India\",\"South Korea\",\n",
    "    \"Canada\",\"Australia-NZ\",\"Taiwan\",\"Mexico\",\"Russia\",\"Brazil\",\"South Africa\",\"Argentina\"\n",
    "]\n",
    "REGION_MAP = {\"Europe non EU\": \"Europe_Non_EU\", \"Australia-NZ\": \"Australia_NZ\"}\n",
    "\n",
    "# Fixed BAU carbon prices ($/tCO2) — strict (no fallback) for MAIN run\n",
    "REGIONAL_BAU_FIXED = {\n",
    "    \"USA\": 23.0, \"EU-15\": 70.0, \"Europe_Non_EU\": 60.0, \"Japan\": 4.0,\n",
    "    \"China\": 11.8, \"India\": 2.0, \"South Korea\": 6.0, \"Canada\": 66.0,\n",
    "    \"Australia_NZ\": 26.0, \"Taiwan\": 9.0, \"Mexico\": 3.9, \"Russia\": 2.0,\n",
    "    \"Brazil\": 2.0, \"South Africa\": 12.8, \"Argentina\": 5.3,\n",
    "}\n",
    "\n",
    "HORIZONS = [2030, 2050]\n",
    "T0_ANCHOR = 2020\n",
    "DISCOUNT_RATES_MAIN = [0.02, 0.00]   # main: r=2% and r=0%\n",
    "DISCOUNT_RATES_20   = [0.02]         # BAU=$20 run: r=2% only\n",
    "\n",
    "# ---- NGFS sector names & order (10 columns) ----\n",
    "SECTOR_ORDER_FIXED = [\n",
    "    \"Supply\",\n",
    "    \"Other Energy Supply\",\n",
    "    \"Electricity\",\n",
    "    \"Industry\",\n",
    "    \"Other Industry\",\n",
    "    \"Chemicals\",\n",
    "    \"Cement\",\n",
    "    \"Transportation\",\n",
    "    \"AFOLU\",\n",
    "    \"Other\",\n",
    "]\n",
    "SUPPLY_COMPONENTS = [\"Electricity\", \"Other Energy Supply\"]\n",
    "\n",
    "# --------------------------- HELPERS ---------------------------\n",
    "def read_sheet(path, sheetname=\"data\"):\n",
    "    if not os.path.exists(path): raise FileNotFoundError(path)\n",
    "    xls = pd.ExcelFile(path)\n",
    "    if sheetname not in xls.sheet_names: raise ValueError(f\"'{sheetname}' not in {xls.sheet_names}\")\n",
    "    return pd.read_excel(xls, sheet_name=sheetname)\n",
    "\n",
    "def longify_years(df, id_vars):\n",
    "    year_cols = [c for c in df.columns if str(c).isdigit()]\n",
    "    out = df.melt(id_vars=id_vars, value_vars=year_cols, var_name=\"Year\", value_name=\"Value\")\n",
    "    out[\"Year\"] = out[\"Year\"].astype(int)\n",
    "    return out.dropna(subset=[\"Value\"])\n",
    "\n",
    "def filter_kyoto(df_long):\n",
    "    return df_long[df_long[\"Variable\"].astype(str).str.startswith(\"Emissions|Kyoto Gases|\")].copy()\n",
    "\n",
    "# Map last-token to NGFS labels (case-insensitive); common synonyms included.\n",
    "_CANON = {\n",
    "    \"supply\": \"Supply\",\n",
    "    \"other energy supply\": \"Other Energy Supply\",\n",
    "    \"electricity\": \"Electricity\", \"power\": \"Electricity\",\n",
    "    \"industry\": \"Industry\",\n",
    "    \"other industry\": \"Other Industry\",\n",
    "    \"chemicals\": \"Chemicals\",\n",
    "    \"cement\": \"Cement\",\n",
    "    \"transportation\": \"Transportation\", \"transport\": \"Transportation\",\n",
    "    \"afolu\": \"AFOLU\",\n",
    "    \"other\": \"Other\",\n",
    "}\n",
    "def ngfs_sector(variable: str) -> str:\n",
    "    last = str(variable).split(\"|\")[-1].strip().lower()\n",
    "    return _CANON.get(last, \"Other\")\n",
    "\n",
    "def resolve_regions(req, rmap, available):\n",
    "    mapped = [rmap.get(r, r) for r in req]\n",
    "    present = [r for r in mapped if r in available]\n",
    "    reverse = {rmap.get(k, k): k for k in req}\n",
    "    return present, reverse\n",
    "\n",
    "def discount_factors(years, r, t0=T0_ANCHOR):\n",
    "    years = np.asarray(years, dtype=int)\n",
    "    return pd.Series((1.0 + r)**(-(years - t0)), index=years)\n",
    "\n",
    "def per_heatmap_vmax(matrix, p=97):\n",
    "    vals = matrix.values.ravel().astype(float)\n",
    "    vals = vals[np.isfinite(vals)]\n",
    "    return max(np.nanpercentile(vals, p), 1e-12) if vals.size else 1.0\n",
    "\n",
    "def slugify(s: str) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9._-]+\", \"_\", s).strip(\"_\")\n",
    "\n",
    "# --------------------------- LOAD DATA ---------------------------\n",
    "em_raw = read_sheet(EMISSIONS_XLSX, \"data\")\n",
    "em_raw[\"Region\"] = em_raw[\"Region\"].astype(str).str.split(\"|\").str[-1]\n",
    "em_long = longify_years(em_raw, [\"Model\",\"Scenario\",\"Region\",\"Variable\",\"Unit\"])\n",
    "em_long = filter_kyoto(em_long)\n",
    "\n",
    "pr_raw = read_sheet(PRICES_XLSX, \"data\")\n",
    "pr_raw[\"Region\"] = pr_raw[\"Region\"].astype(str).str.split(\"|\").str[-1]\n",
    "pr_long = longify_years(pr_raw, [\"Model\",\"Scenario\",\"Region\",\"Variable\",\"Unit\"])\n",
    "\n",
    "# Regions intersection & order\n",
    "avail_regions = set(em_long[\"Region\"].unique()) & set(pr_long[\"Region\"].unique())\n",
    "regions_order, reverse = resolve_regions(REQUESTED_REGIONS, REGION_MAP, avail_regions)\n",
    "em_long = em_long[em_long[\"Region\"].isin(regions_order)].copy()\n",
    "pr_long = pr_long[pr_long[\"Region\"].isin(regions_order)].copy()\n",
    "\n",
    "# ---- Strict BAU fixed-price coverage for MAIN run ----\n",
    "missing_bau = [r for r in regions_order if r not in REGIONAL_BAU_FIXED]\n",
    "if missing_bau:\n",
    "    raise ValueError(f\"Missing BAU fixed price for regions: {missing_bau}\")\n",
    "nonpos_bau = [r for r,v in REGIONAL_BAU_FIXED.items() if r in regions_order and (v is None or v <= 0)]\n",
    "if nonpos_bau:\n",
    "    raise ValueError(f\"Non-positive BAU fixed price for regions: {nonpos_bau}\")\n",
    "\n",
    "# --------------------------- PREP SERIES ---------------------------\n",
    "def pivot_emissions(df, scenario, year_max):\n",
    "    d = df[(df[\"Scenario\"]==scenario) & (df[\"Year\"]<=year_max)].copy()\n",
    "    d[\"Sector\"] = d[\"Variable\"].apply(ngfs_sector)\n",
    "    return d.rename(columns={\"Value\":\"E\"})\n",
    "\n",
    "def nz_prices_region(df, year_max):\n",
    "    d = df[(df[\"Scenario\"]==NZ_SCEN) & (df[\"Year\"]<=year_max) &\n",
    "           (df[\"Variable\"].astype(str).str.fullmatch(r\"Price\\|Carbon\"))][[\"Region\",\"Year\",\"Value\"]]\n",
    "    if d.empty:\n",
    "        raise ValueError(\"No region-level NZ 'Price|Carbon' found in PRICES_XLSX.\")\n",
    "    return d.rename(columns={\"Value\":\"Pz_reg\"})\n",
    "\n",
    "# --------------------------- METRIC (Eq. 9) ---------------------------\n",
    "def compute_eq9_matrix(H, r_disc, bau_price_spec):\n",
    "    \"\"\"\n",
    "    bau_price_spec: either a dict {Region -> price} or a float (constant for all regions).\n",
    "    \"\"\"\n",
    "    Eb = pivot_emissions(em_long, BAU_SCEN, H).rename(columns={\"E\":\"E_b\"})\n",
    "    Ez = pivot_emissions(em_long, NZ_SCEN,  H).rename(columns={\"E\":\"E_z\"})\n",
    "    key = [\"Region\",\"Variable\",\"Unit\",\"Year\",\"Sector\"]\n",
    "    m = Eb[key+[\"E_b\"]].merge(Ez[key+[\"E_z\"]], on=key, how=\"inner\")\n",
    "\n",
    "    # NZ region-level prices\n",
    "    Pz = nz_prices_region(pr_long, H)\n",
    "    m = m.merge(Pz, on=[\"Region\",\"Year\"], how=\"left\")\n",
    "\n",
    "    # Fixed BAU price per region\n",
    "    if isinstance(bau_price_spec, dict):\n",
    "        m[\"Pb_den\"] = m[\"Region\"].map(bau_price_spec).astype(float)\n",
    "        if m[\"Pb_den\"].isna().any():\n",
    "            bad = m.loc[m[\"Pb_den\"].isna(),\"Region\"].unique().tolist()\n",
    "            raise ValueError(f\"BAU fixed price unexpectedly missing after mapping for: {bad}\")\n",
    "    else:\n",
    "        # constant for all regions (e.g., 20.0)\n",
    "        m[\"Pb_den\"] = float(bau_price_spec)\n",
    "\n",
    "    # (E_b - E_z)_+\n",
    "    m[\"Excess_pos\"] = np.clip(m[\"E_b\"] - m[\"E_z\"], 0.0, None)\n",
    "\n",
    "    # Discount\n",
    "    years = sorted(m[\"Year\"].unique())\n",
    "    D = discount_factors(years, r=r_disc, t0=T0_ANCHOR)\n",
    "    m = m.merge(D.rename(\"D\").rename_axis(\"Year\").reset_index(), on=\"Year\", how=\"left\")\n",
    "\n",
    "    # Per-row contributions\n",
    "    m[\"Num_t\"] = m[\"D\"] * m[\"Pz_reg\"] * m[\"Excess_pos\"]\n",
    "    m[\"Den_t\"] = m[\"D\"] * m[\"Pb_den\"] * m[\"E_b\"]\n",
    "\n",
    "    # Group by (Region, Sector)\n",
    "    grp = (m.groupby([\"Region\",\"Sector\"], as_index=False)[[\"Num_t\",\"Den_t\"]].sum())\n",
    "\n",
    "    # If 'Supply' is missing but components exist, synthesize it\n",
    "    present = set(grp[\"Sector\"].unique())\n",
    "    if (\"Supply\" not in present) and all(s in present for s in SUPPLY_COMPONENTS):\n",
    "        supply = (grp[grp[\"Sector\"].isin(SUPPLY_COMPONENTS)]\n",
    "                    .groupby(\"Region\", as_index=False)[[\"Num_t\",\"Den_t\"]].sum())\n",
    "        supply[\"Sector\"] = \"Supply\"\n",
    "        grp = pd.concat([grp, supply], ignore_index=True)\n",
    "\n",
    "    # Final ratio\n",
    "    grp[\"Eq9_Ctilde\"] = np.where(grp[\"Den_t\"] > 0, grp[\"Num_t\"]/grp[\"Den_t\"], np.nan)\n",
    "\n",
    "    # Pivot to matrix with fixed NGFS order\n",
    "    mat = grp.pivot(index=\"Region\", columns=\"Sector\", values=\"Eq9_Ctilde\")\n",
    "    mat = mat.reindex(index=regions_order)\n",
    "    for col in SECTOR_ORDER_FIXED:\n",
    "        if col not in mat.columns:\n",
    "            mat[col] = np.nan\n",
    "    mat = mat[SECTOR_ORDER_FIXED]\n",
    "    return mat\n",
    "\n",
    "# --------------------------- PLOTTING ---------------------------\n",
    "def plot_heatmap(mat, title, rotate_xticks=True):\n",
    "    import seaborn as sns\n",
    "    fig, ax = plt.subplots(figsize=(0.5*max(8, mat.shape[1]) + 6,\n",
    "                                    0.45*max(6, mat.shape[0]) + 3))\n",
    "    cm = plt.get_cmap(\"RdYlGn_r\").copy()\n",
    "    try: cm.set_bad('#e6e6e6')\n",
    "    except: pass\n",
    "    vmax = per_heatmap_vmax(mat, p=97)\n",
    "    sns.heatmap(mat.clip(lower=0, upper=vmax), ax=ax, cmap=cm,\n",
    "                vmin=0, vmax=vmax, mask=np.isnan(mat.values),\n",
    "                linewidths=0.2, linecolor='white', cbar=False)\n",
    "    if rotate_xticks:\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=9)\n",
    "    ax.set_title(title, fontsize=11); ax.set_xlabel(\"Sector\"); ax.set_ylabel(\"Region\")\n",
    "    im = ax.collections[0]\n",
    "    cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.02)\n",
    "    cbar.set_label(r\"$\\tilde{C}^{z|b}$\")  # notation per your doc\n",
    "    ax.text(0.99, 1.02, f\"p97≈{vmax:.2g}\", transform=ax.transAxes,\n",
    "            ha=\"right\", va=\"bottom\", fontsize=8, color=\"#555\")\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(bottom=0.18)\n",
    "    return fig\n",
    "\n",
    "# --------------------------- UTIL: RUN + SAVE ---------------------------\n",
    "def run_and_export(pdf_path, png_dir, discount_rates, bau_price_spec, title_suffix):\n",
    "    os.makedirs(png_dir, exist_ok=True)\n",
    "    with PdfPages(pdf_path) as pp:\n",
    "        # Cover\n",
    "        fig = plt.figure(figsize=(11, 8.5)); plt.axis(\"off\")\n",
    "        bullets = [\n",
    "            r\"Eq. (9): $\\tilde{C}^{z|b} = \\frac{\\sum_t D_t P^z_{r,t}(E^b-E^z)_+}{\\sum_t D_t P^{b,\\mathrm{fixed}}_r E^b}$\",\n",
    "            \"NZ price: region-level Price|Carbon from PRICES_XLSX.\",\n",
    "            f\"Sectors (NGFS): \" + \", \".join(SECTOR_ORDER_FIXED),\n",
    "            f\"Horizons: 2020–2030, 2020–2050. Discount rates: \" +\n",
    "            \", \".join([f\"{int(r*100)}%\" for r in discount_rates]) + f\" (t0 = {T0_ANCHOR}).\",\n",
    "        ]\n",
    "        if isinstance(bau_price_spec, dict):\n",
    "            bullets.insert(2, \"BAU prices: region-specific fixed values.\")\n",
    "        else:\n",
    "            bullets.insert(2, f\"BAU price: fixed = ${bau_price_spec:g}/tCO₂ for all regions.\")\n",
    "        y = 0.92\n",
    "        plt.text(0.05, y, f\"Transition Cost — Eq. (9) Heatmaps {title_suffix}\", fontsize=16, weight=\"bold\"); y -= 0.06\n",
    "        for b in bullets:\n",
    "            plt.text(0.05, y, u\"\\u2022  \" + b, fontsize=11); y -= 0.035\n",
    "        plt.text(0.05, 0.06, f\"Inputs: {os.path.basename(EMISSIONS_XLSX)}, {os.path.basename(PRICES_XLSX)}\",\n",
    "                 fontsize=9, color=\"#555\")\n",
    "        pp.savefig(fig); plt.close(fig)\n",
    "\n",
    "        # Pages\n",
    "        for r_disc in discount_rates:\n",
    "            for H in HORIZONS:\n",
    "                mat = compute_eq9_matrix(H, r_disc, bau_price_spec)\n",
    "                ttl = f\"Eq. (9) — Normalized Transition Cost, 2020–{H} (r={int(r_disc*100)}%) {title_suffix}\"\n",
    "                fig = plot_heatmap(mat, ttl, rotate_xticks=True)\n",
    "                pp.savefig(fig)\n",
    "                # Save PNG\n",
    "                fn = f\"Eq9_{int(r_disc*100)}pct_{H}{'_BAU20' if not isinstance(bau_price_spec, dict) else ''}.png\"\n",
    "                fig.savefig(os.path.join(png_dir, slugify(fn)), dpi=300, bbox_inches=\"tight\")\n",
    "                plt.close(fig)\n",
    "\n",
    "    print(f\"[OK] PDF -> {pdf_path}\\n[OK] PNGs -> {png_dir}\")\n",
    "\n",
    "# --------------------------- RUN BOTH SCENARIOS ---------------------------\n",
    "# 1) Main: regional BAU prices, r∈{2%,0%}\n",
    "run_and_export(\n",
    "    pdf_path=PDF_OUT_MAIN,\n",
    "    png_dir=PNG_DIR_MAIN,\n",
    "    discount_rates=DISCOUNT_RATES_MAIN,\n",
    "    bau_price_spec=REGIONAL_BAU_FIXED,\n",
    "    title_suffix=\"(Regional BAU fixed prices)\"\n",
    ")\n",
    "\n",
    "# 2) Special: BAU fixed = $20/tCO2 for all regions, r=2%\n",
    "run_and_export(\n",
    "    pdf_path=PDF_OUT_20,\n",
    "    png_dir=PNG_DIR_20,\n",
    "    discount_rates=DISCOUNT_RATES_20,\n",
    "    bau_price_spec=20.0,\n",
    "    title_suffix=\"(BAU fixed = $20/tCO₂)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c103f1-26cf-4888-b0fd-526d1f81fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "for p in [EMISSIONS_XLSX, PRICES_XLSX if 'PRICES_XLSX' in globals() else None]:\n",
    "    if p:\n",
    "        assert Path(p).exists(), f\"Missing: {p}\"\n",
    "print(\"Inputs OK. PDF/PNG will be written under:\", in_out(\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6015c938-11ad-4868-8e91-52bd9a454d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/noenotter/E4S\n",
      "Contents here: ['Streamlit_TR_PR.ipynb', 'NGFS_Transition_Risk_Heatmaps.ipynb', 'NGFS_Physical_Risks_Heatmaps.ipynb', 'OLD', 'NGFS_Physical_Risk_Data_Base.ipynb', '.ipynb_checkpoints', 'ngfs_shortterm_trimmed']\n",
      "Checking: /Users/noenotter/E4S\n",
      "  has lib/? False\n",
      "  has config.yaml? False\n",
      "Checking: /Users/noenotter\n",
      "  has lib/? False\n",
      "  has config.yaml? False\n",
      "Checking: /Users\n",
      "  has lib/? False\n",
      "  has config.yaml? False\n",
      "Checking: /\n",
      "  has lib/? False\n",
      "  has config.yaml? False\n",
      "Checking: /\n",
      "  has lib/? False\n",
      "  has config.yaml? False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CWD:\", os.getcwd())                     # where Jupyter started\n",
    "print(\"Contents here:\", os.listdir(os.getcwd()))\n",
    "\n",
    "cur = Path.cwd()\n",
    "for i in range(5):  # climb max 5 levels\n",
    "    print(\"Checking:\", cur)\n",
    "    print(\"  has lib/?\", (cur / \"lib\").exists())\n",
    "    print(\"  has config.yaml?\", (cur / \"config.yaml\").exists())\n",
    "    cur = cur.parent\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
